{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "In this chapter, we will be using the MNIST dataset, which is a set of 70,000 small\n",
    "images of digits handwritten by high school students and employees of the US Census\n",
    "Bureau. \n",
    "\n",
    "Each image is labeled with the digit it represents. \n",
    "\n",
    "This set has been studied\n",
    "so much that it is often called the “Hello World” of Machine Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "from six.moves import urllib\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from scipy.io import loadmat\n",
    "mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
    "mnist_path = \"./mnist-original.mat\"\n",
    "response = urllib.request.urlopen(mnist_alternative_url)\n",
    "with open(mnist_path, \"wb\") as f:\n",
    "    content = response.read()\n",
    "    f.write(content)\n",
    "mnist_raw = loadmat(mnist_path)\n",
    "mnist = {\n",
    "    \"data\": mnist_raw[\"data\"].T,\n",
    "    \"target\": mnist_raw[\"label\"][0],\n",
    "    \"COL_NAMES\": [\"label\", \"data\"],\n",
    "    \"DESCR\": \"mldata.org dataset: mnist-original\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets loaded by Scikit-Learn generally have a similar dictionary structure including:\n",
    "- A DESCR key describing the dataset\n",
    "- A data key containing an array with one row per instance and one column per feature\n",
    "- A target key containing an array with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 70,000 images and each image has 784 features.\n",
    "  - why so many?\n",
    "       - each image is 28x28 pixels and each feature simply represents one pixel's intensity from 0(white) to 255(black)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one digit from the dataset.\n",
    "\n",
    "<b> How? </b>\n",
    "\n",
    "Grab an instance's feature vector, reshape it to a 28x28 array and display with matplotlib imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[36000]\n",
    "some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary,\n",
    "            interpolation=\"nearest\")\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a 5, let's see what the label says"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should always create a test set and set it aside before inspecting the data\n",
    "closely. \n",
    "\n",
    "The MNIST dataset is actually already split into a training set (the first 60,000\n",
    "images) and a test set (the last 10,000 images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s also shuffle the training set; this will guarantee that all cross-validation folds will\n",
    "be similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> But why? </u>\n",
    "\n",
    "Some learning algorithms are sensitive to the order of the training instances, and they perform\n",
    "poorly if they get many similar instances in a row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> When is shuffling a bad idea? </u>\n",
    "\n",
    "TIME SERIES DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training a binary classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s simplify the problem for now and only try to identify one digit—for example,\n",
    "the number 5. This “5-detector” will be an example of a binary classifier, capable of\n",
    "distinguishing between just two classes, 5 and not-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the target vectors for this task\n",
    "\n",
    "y_train_5 = (y_train == 5)  # true for all 5s, false for anything else\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick a classifier and train it\n",
    "\n",
    "Good starting point: Stochastic gradient descent (SGD) classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> Why SGD? </u>\n",
    "\n",
    "This classifier has the <b> advantage of being capable of handling \n",
    "very large datasets efficiently. </b>\n",
    "\n",
    "This is in part because SGD deals with training instances independently, one at a time\n",
    "(which also makes SGD well suited for online learning),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
